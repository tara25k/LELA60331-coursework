{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "reviews=[]\n",
    "sentiment_ratings=[]\n",
    "product_types=[]\n",
    "helpfulness_ratings=[]\n",
    "\n",
    "with open(\"Compiled_Reviews.txt\") as f:\n",
    "   for line in f.readlines()[1:]:\n",
    "        fields = line.rstrip().split('\\t')\n",
    "        reviews.append(fields[0])\n",
    "        sentiment_ratings.append(fields[1])\n",
    "        product_types.append(fields[2])\n",
    "        helpfulness_ratings.append(fields[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD IN STOPWORDS\n",
    "f = open(\"data/stopwords.txt\", \"r\")\n",
    "stopwords = []\n",
    "for line in f:\n",
    "    stopwords.append(line.strip())\n",
    "f.close()\n",
    "\n",
    "punct = ['#', '\"', '\"\"', '%', '$', '&', ')', '(', '+', '*', '-'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOKENISE REVIEWS FOR VOCABULARY\n",
    "\n",
    "token_def = re.compile(\"[^ \\.?!:,)(\\\"]+\")\n",
    "tokenized_sents = [token_def.findall(txt) for txt in reviews]\n",
    "tokens=[]\n",
    "for s in tokenized_sents:\n",
    "    filtered_tokens = [t.lower() for t in s if t.lower() not in stopwords and t not in punct]\n",
    "\n",
    "    # Add unigrams\n",
    "    tokens.extend(filtered_tokens)\n",
    "\n",
    "    # Add bigrams\n",
    "    tokens.extend([f\"{filtered_tokens[i]}_{filtered_tokens[i+1]}\" for i in range(len(filtered_tokens) - 1)])\n",
    "\n",
    "\n",
    "tokens = [t for t in tokens if t not in stopwords and t not in punct]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET VOCABULARY - 5000 MOST COMMON WORDS\n",
    "\n",
    "counts=Counter(tokens)\n",
    "so=sorted(counts.items(), key=lambda item: item[1], reverse=True)\n",
    "so=list(zip(*so))[0]\n",
    "\n",
    "# get 5000 most common into vocabulary\n",
    "type_list=so[0:5000]\n",
    "vocab_list = type_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.zeros((len(reviews), len(vocab_list)))\n",
    "print(len(reviews))\n",
    "for i, rev in enumerate(reviews):\n",
    "    if i%1000 == 0:\n",
    "         print(i)\n",
    "\n",
    "    tokens = [t.lower() for t in token_def.findall(rev) if t.lower() not in stopwords and t not in punct]\n",
    "\n",
    "    # Generate bigrams\n",
    "    bigrams = [f\"{tokens[j]}_{tokens[j+1]}\" for j in range(len(tokens) - 1)]\n",
    "\n",
    "    # Combine unigrams and bigrams\n",
    "    all_tokens = tokens + bigrams\n",
    "    # for stemming\n",
    "    # tokens = [stem_word(token) for token in tokens]\n",
    "\n",
    "    # iterate over vocab\n",
    "    for j, vocab_token in enumerate(vocab_list):\n",
    "        # if the current word j occurs in the current review i then set the matrix element at i,j to be one. Otherwise leave as zero.\n",
    "        if vocab_token in all_tokens:\n",
    "              M[i,j] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ints=np.random.choice(len(reviews),int(len(reviews)*0.8),replace=False)\n",
    "train_ints = train_ints.tolist()\n",
    "test_ints=list(set(range(0,len(reviews))) - set(train_ints))\n",
    "M_train = M[train_ints,]\n",
    "M_test = M[test_ints,]\n",
    "\n",
    "# for labels, use a vector representation\n",
    "labels_train = [sentiment_ratings[i] for i in train_ints]\n",
    "labels_test = [sentiment_ratings[i] for i in test_ints]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y has to be an vector of integers (0 for negative 1 for positive)\n",
    "y=np.array([int(l == \"positive\") for l in labels_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([int(l == \"positive\") for l in labels_train])  # Convert to cp.ndarray\n",
    "# initialise variables\n",
    "num_features=len(vocab_list)\n",
    "hidden_size = 3000\n",
    "weights_0_1 = np.random.randn(num_features, hidden_size)\n",
    "weights_1_2 = np.random.randn(hidden_size, 1)\n",
    "bias_1 = np.random.randn(hidden_size)  # Shape: (100,)\n",
    "bias_2 = np.random.rand(1)  # Shape: (1,)\n",
    "n_iters = 2500\n",
    "lr=0.01\n",
    "logistic_loss=[]\n",
    "num_samples=len(y)\n",
    "# previously on iteration 10001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL\n",
    "for i in range(n_iters):\n",
    "    print(f\"Iteration {i}/{n_iters}\")\n",
    "\n",
    "    # forward pass\n",
    "    layer_1 = np.maximum(M_train.dot(weights_0_1) + bias_1, 0)\n",
    "    layer_2 = layer_1.dot(weights_1_2) + bias_2\n",
    "    q = 1/(1+np.exp(-layer_2))\n",
    "\n",
    "    # difference between actual labels\n",
    "    diff = (q.T - y)\n",
    "\n",
    "\n",
    "    loss = -np.mean(y * np.log(q.T) + (1 - y) * np.log(1 - q.T))\n",
    "    logistic_loss.append(loss)\n",
    "\n",
    "    # for hidden layer weights\n",
    "    grad_weights_1_2 = layer_1.T.dot(diff.T) / num_samples + (0.001*weights_1_2)\n",
    "    grad_bias_2 = np.sum(diff) / num_samples\n",
    "\n",
    "    # for input layer weights\n",
    "    layer_1_error = diff.T.dot(weights_1_2.T) # errors at hidden nodes\n",
    "    layer_1_delta = layer_1_error * (layer_1 > 0) #Â multiply by relu derivative\n",
    "    grad_weights_0_1 = M_train.T.dot(layer_1_delta) / num_samples + (0.001*weights_0_1)\n",
    "    grad_bias_1 = np.sum(layer_1_delta, axis=0) / num_samples\n",
    "\n",
    "    # update weights\n",
    "    weights_0_1 -= lr * grad_weights_0_1\n",
    "    weights_1_2 -= lr * grad_weights_1_2\n",
    "    bias_1 -= lr * grad_bias_1\n",
    "    bias_2 -= lr * grad_bias_2\n",
    "\n",
    "\n",
    "logistic_loss_np = np.array([loss.get() for loss in logistic_loss])\n",
    "\n",
    "# Plot the loss\n",
    "plt.plot(range(1, n_iters), logistic_loss_np[1:])\n",
    "plt.xlabel(\"Number of Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Logistic Loss Over Iterations\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATE ON TEST SET\n",
    "layer_1 = np.maximum(M_test.dot(weights_0_1) + bias_1, 0)\n",
    "layer_2 = layer_1.dot(weights_1_2) + bias_2\n",
    "q = 1/(1+np.exp(-layer_2))\n",
    "\n",
    "y_test_pred = [int(prob > 0.5) for prob in q] \n",
    "y_test=[int(l == \"positive\") for l in labels_test]\n",
    "\n",
    "\n",
    "# EVALUATION METRICS\n",
    "# accuracy\n",
    "acc_test=[int(yp == y_test[s]) for s,yp in enumerate(y_test_pred)]\n",
    "print(f'accuracy: {sum(acc_test)/len(acc_test)}')\n",
    "\n",
    "# precision and recall\n",
    "labels_test_pred=[\"positive\" if s == 1 else \"negative\" for s in y_test_pred]\n",
    "true_positives=sum([int(yp == \"positive\" and labels_test[s] == \"positive\") for s,yp in enumerate(labels_test_pred)])\n",
    "false_negatives=sum([int(yp == \"negative\" and labels_test[s] == \"positive\") for s,yp in enumerate(labels_test_pred)])\n",
    "false_positives=sum([int(yp == \"positive\" and labels_test[s] == \"negative\") for s,yp in enumerate(labels_test_pred)])\n",
    "true_negatives=sum([int(yp == \"negative\" and labels_test[s] == \"negative\") for s,yp in enumerate(labels_test_pred)])\n",
    "\n",
    "precision = true_positives/(true_positives + false_positives)\n",
    "recall = true_positives/(true_positives + false_negatives)\n",
    "print(f'precision: {precision}')\n",
    "print(f'recall: {recall}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMINING WEIGHTS\n",
    "all_weights = np.dot(weights_0_1, weights_1_2).flatten()\n",
    "\n",
    "print(\"most impactful words for a positive review:\")\n",
    "print([vocab_list[x] for x in np.argsort(all_weights)[::-1][0:20]])\n",
    "\n",
    "print(\"\\nmost impactful words for a negative review:\")\n",
    "print([vocab_list[x] for x in np.argsort(all_weights)[0:20]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
